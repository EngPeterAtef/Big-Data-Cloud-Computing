{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import col, countDistinct, isnan, when, count, round, substring_index,substring, split, regexp_replace, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LinearSVC\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_vs_target(df, feature):\n",
    "    target = \"MIS_Status\"\n",
    "    # Calculate the percentage of points for each unique value of each feature compared to MIS_Status\n",
    "    percentage_df = df.groupBy(feature, target).agg((count(\"*\") / df.count()).alias(\"Percentage\"))\n",
    "\n",
    "    # Round percentage values to two decimal places\n",
    "    percentage_df = percentage_df.withColumn(\"Percentage\", round(col(\"Percentage\") * 100, 2))\n",
    "\n",
    "    # Show result\n",
    "    percentage_df.show()\n",
    "\n",
    "    # Convert DataFrame to list\n",
    "    data = percentage_df.collect()\n",
    "\n",
    "    # Separate data by target\n",
    "    data_0 = [row['Percentage'] for row in data if row[target] == 0]\n",
    "    data_1 = [row['Percentage'] for row in data if row[target] == 1]\n",
    "\n",
    "    # Create traces\n",
    "    trace0 = go.Bar(x=[row[feature] for row in data if row[target] == 0], y=data_0, name='0', marker_color='red')\n",
    "    trace1 = go.Bar(x=[row[feature] for row in data if row[target] == 1], y=data_1, name='1', marker_color='blue')\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(barmode='stack', title='Percentage Distribution of ' + feature + ' vs ' + target)\n",
    "\n",
    "    # Create figure and add traces\n",
    "    fig = go.Figure(data=[trace0, trace1], layout=layout)\n",
    "\n",
    "    # Plot\n",
    "    fig.show()\n",
    "\n",
    "def features_vs_target(df, features):\n",
    "    target = \"MIS_Status\"\n",
    "    num_cols = 4\n",
    "    # Calculate the number of rows needed for the grid\n",
    "    num_rows = (len(features) // num_cols) + 1  # Ceiling division to get the number of rows needed\n",
    "\n",
    "    # Create a subplot grid with four columns\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[f\"{feat} vs {target}\" for feat in features])\n",
    "\n",
    "    # Initialize row and col counters\n",
    "    row_idx = 1\n",
    "    col_idx = 1\n",
    "\n",
    "    for feature in features:\n",
    "        # Calculate the percentage of points for each unique value of each feature compared to MIS_Status\n",
    "        percentage_df = df.groupBy(feature, target).agg((count(\"*\") / df.count()).alias(\"Percentage\"))\n",
    "\n",
    "        # Round percentage values to two decimal places\n",
    "        percentage_df = percentage_df.withColumn(\"Percentage\", round(col(\"Percentage\") * 100, 2))\n",
    "\n",
    "        # Convert DataFrame to list\n",
    "        data = percentage_df.collect()\n",
    "\n",
    "        # Separate data by target\n",
    "        data_0 = [row['Percentage'] for row in data if row[target] == 0]\n",
    "        data_1 = [row['Percentage'] for row in data if row[target] == 1]\n",
    "\n",
    "        # Create traces for the current feature\n",
    "        trace0 = go.Bar(x=[row[feature] for row in data if row[target] == 0], y=data_0, name='0', marker_color='red')\n",
    "        trace1 = go.Bar(x=[row[feature] for row in data if row[target] == 1], y=data_1, name='1', marker_color='blue')\n",
    "\n",
    "        # Add traces to the subplot\n",
    "        fig.add_trace(trace0, row=row_idx, col=col_idx)\n",
    "        fig.add_trace(trace1, row=row_idx, col=col_idx)\n",
    "\n",
    "        # Move to the next cell\n",
    "        col_idx += 1\n",
    "        if col_idx > num_cols:\n",
    "            col_idx = 1\n",
    "            row_idx += 1\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(height=600*num_rows, title_text=f\"Percentage Distribution of Features vs {target}\", showlegend=False)\n",
    "\n",
    "    # Plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"LoanApproval\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc=spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Read Data - SBAnational.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path=\"../data/SBAnational.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, quote='\"', escape='\"', multiLine=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = loan_df.columns\n",
    "features_vs_target(loan_df, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 9. ApprovalMonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop approval month as it is needed only in EDA not training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loan_df =loan_df.drop(\"ApprovalMonth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
