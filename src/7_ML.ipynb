{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chbic3fo9AJR"
      },
      "source": [
        " ## Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfpbvgavADeB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7LveuaXi9AJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC,GBTClassifier\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcITIKfJAJ9G"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FtFnxOG2AMkv"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_data, validation_data = None, test_data = None, model_name = \"Model\", label_column = \"MIS_Status\"):\n",
        "    # Evaluate training data\n",
        "    train_predictions = model.transform(train_data)\n",
        "    train_metrics = calculate_metrics(train_predictions, label_column)\n",
        "\n",
        "     # Prepare data for tabulate\n",
        "    table = [\n",
        "        ['Model', model_name],\n",
        "        ['Metric', 'Training'],\n",
        "        ['Accuracy', train_metrics['accuracy']],\n",
        "        ['Weighted Precision', train_metrics['weighted_precision']],\n",
        "        ['Weighted Recall', train_metrics['weighted_recall']],\n",
        "        ['F1 Score', train_metrics['f1']]\n",
        "    ]\n",
        "    # Evaluate validation data\n",
        "    if validation_data is not None:\n",
        "        validation_predictions = model.transform(validation_data)\n",
        "        validation_metrics = calculate_metrics(validation_predictions, label_column)\n",
        "        table[0] += ['']\n",
        "        table[1] += ['Validation']\n",
        "        table[2] += [validation_metrics['accuracy']]\n",
        "        table[3] += [validation_metrics['weighted_precision']]\n",
        "        table[4] += [validation_metrics['weighted_recall']]\n",
        "        table[5] += [validation_metrics['f1']]\n",
        "\n",
        "    # Evaluate test data\n",
        "    if test_data is not None:\n",
        "        test_predictions = model.transform(test_data)\n",
        "        test_metrics = calculate_metrics(test_predictions, label_column)\n",
        "        table[0] += ['']\n",
        "        table[1] += ['Test']\n",
        "        table[2] += [test_metrics['accuracy']]\n",
        "        table[3] += [test_metrics['weighted_precision']]\n",
        "        table[4] += [test_metrics['weighted_recall']]\n",
        "        table[5] += [test_metrics['f1']]\n",
        "\n",
        "\n",
        "    # Display results using tabulate\n",
        "    print(tabulate(table, headers=\"firstrow\", tablefmt='grid'))\n",
        "\n",
        "def calculate_metrics(predictions, label_column):\n",
        "    evaluator_multi = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='accuracy')\n",
        "    evaluator_weighted_precision = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedPrecision')\n",
        "    evaluator_weighted_recall = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedRecall')\n",
        "    evaluator_f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='f1')\n",
        "\n",
        "    accuracy = evaluator_multi.evaluate(predictions)\n",
        "    weighted_precision = evaluator_weighted_precision.evaluate(predictions)\n",
        "    weighted_recall = evaluator_weighted_recall.evaluate(predictions)\n",
        "    f1 = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'weighted_precision': weighted_precision,\n",
        "        'weighted_recall': weighted_recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OcvZDw5A9AJT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# spark=SparkSession.builder\\\n",
        "#     .master(\"local[*]\")\\\n",
        "#     .appName(\"LoanApproval\")\\\n",
        "#     .getOrCreate()\n",
        "spark=SparkSession.builder\\\n",
        "    .appName(\"LoanApproval\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HnF7W69AJU"
      },
      "source": [
        " ## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1HbGwdzc9AJU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# data_path=\"/content/drive/MyDrive/Colab Notebooks/BD_project/50000.csv\"\n",
        "# data_path=\"../sample_data/50000_1.csv\"\n",
        "data_path=\"../data/preprocessed_2.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JjluWYjC9AJU"
      },
      "outputs": [],
      "source": [
        "\n",
        "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDD_RBf9AJU",
        "outputId": "b8665171-c592-4229-a752-3348289ba566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- State: string (nullable = true)\n",
            " |-- Bank: string (nullable = true)\n",
            " |-- BankState: string (nullable = true)\n",
            " |-- Term: integer (nullable = true)\n",
            " |-- NoEmp: integer (nullable = true)\n",
            " |-- NewExist: integer (nullable = true)\n",
            " |-- CreateJob: integer (nullable = true)\n",
            " |-- UrbanRural: integer (nullable = true)\n",
            " |-- RevLineCr: integer (nullable = true)\n",
            " |-- LowDoc: integer (nullable = true)\n",
            " |-- Sector: integer (nullable = true)\n",
            " |-- IsFranchise: integer (nullable = true)\n",
            " |-- clean_DisbursementGross: double (nullable = true)\n",
            " |-- MIS_Status: integer (nullable = true)\n",
            " |-- clean_GrAppv: double (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|UrbanRural|RevLineCr|LowDoc|Sector|IsFranchise|clean_DisbursementGross|MIS_Status|clean_GrAppv|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|         1|        1|     0|    44|          0|                25959.0|         1|     10000.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|         1|        1|     0|    23|          0|                98479.0|         1|     50000.0|\n",
            "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|         1|        1|     0|    23|          0|               135070.0|         1|     35000.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|         1|        0|     0|    72|          0|                20000.0|         1|     20000.0|\n",
            "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|         0|        0|     1|    81|          0|                50000.0|         1|     50000.0|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loan_df.printSchema()\n",
        "loan_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPp_5zgk9AJU",
        "outputId": "b20f8619-2703-4c4d-ff6e-7a22d13a82f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transforming categorial features...\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+--------------------+\n",
            "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|UrbanRural|RevLineCr|LowDoc|Sector|IsFranchise|clean_DisbursementGross|MIS_Status|clean_GrAppv|StateIndex|      StateVec|BankIndex|           BankVec|BankStateIndex|   BankStateVec|UrbanRuralIndex|UrbanRuralVec|RevLineCrIndex| RevLineCrVec|LowDocIndex|    LowDocVec|SectorIndex|     SectorVec|            features|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+--------------------+\n",
            "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|         1|        1|     0|    44|          0|                25959.0|         1|     10000.0|       7.0|(51,[7],[1.0])|     13.0| (5468,[13],[1.0])|           9.0| (54,[9],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        1.0|(20,[1],[1.0])|(5604,[0,1,5,6,14...|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|         1|        1|     0|    23|          0|                98479.0|         1|     50000.0|       7.0|(51,[7],[1.0])|      3.0|  (5468,[3],[1.0])|           4.0| (54,[4],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        3.0|(20,[3],[1.0])|(5604,[0,1,5,6,14...|\n",
            "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|         1|        1|     0|    23|          0|               135070.0|         1|     35000.0|       7.0|(51,[7],[1.0])|    580.0|(5468,[580],[1.0])|          15.0|(54,[15],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        3.0|(20,[3],[1.0])|(5604,[0,1,5,6,14...|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|         1|        0|     0|    72|          0|                20000.0|         1|     20000.0|       7.0|(51,[7],[1.0])|      3.0|  (5468,[3],[1.0])|           4.0| (54,[4],[1.0])|            0.0|(2,[0],[1.0])|           0.0|(1,[0],[1.0])|        0.0|(1,[0],[1.0])|        8.0|(20,[8],[1.0])|(5604,[0,1,5,6,14...|\n",
            "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|         0|        0|     1|    81|          0|                50000.0|         1|     50000.0|       7.0|(51,[7],[1.0])|      0.0|  (5468,[0],[1.0])|          15.0|(54,[15],[1.0])|            1.0|(2,[1],[1.0])|           0.0|(1,[0],[1.0])|        1.0|    (1,[],[])|        5.0|(20,[5],[1.0])|(5604,[0,1,2,5,6,...|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Splitting data into training, validation and test...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Transforming categorial features...\")\n",
        "# List of categorical columns to be one-hot encoded\n",
        "# categorical_columns = [\"Name\", \"City\", \"State\", \"Zip\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
        "categorical_columns = [\"State\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\"]\n",
        "\n",
        "# Define an empty list to store the pipeline stages\n",
        "stages = []\n",
        "\n",
        "# Iterate over each categorical column\n",
        "for column in categorical_columns:\n",
        "    # Define StringIndexer for the current column\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"Index\")\n",
        "\n",
        "    # Define OneHotEncoder for the indexed column\n",
        "    encoder = OneHotEncoder(inputCol=column + \"Index\", outputCol=column + \"Vec\")\n",
        "\n",
        "    # Add StringIndexer and OneHotEncoder to the list of stages\n",
        "    stages += [indexer, encoder]\n",
        "\n",
        "label_column = \"MIS_Status\"\n",
        "\n",
        "# Create VectorAssembler for combining all features\n",
        "# List of input columns (excluding the label column and categorical columns)\n",
        "input_columns = [col for col in loan_df.columns if col != label_column and col not in categorical_columns]\n",
        "input_columns += [column + \"Vec\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=input_columns , outputCol=\"features\")\n",
        "\n",
        "# Combine all stages into a Pipeline\n",
        "pipeline = Pipeline(stages=stages + [assembler])\n",
        "\n",
        "# Fit the pipeline to your data\n",
        "pipeline_model = pipeline.fit(loan_df)\n",
        "\n",
        "# Transform your data using the pipeline\n",
        "transformed_data = pipeline_model.transform(loan_df)\n",
        "transformed_data.show(5)\n",
        "print(\"Splitting data into training, validation and test...\")\n",
        "# Split the transformed data into training and test sets (60% training, 20% validation, 20% test)\n",
        "(trainingData, validationData, testData) = transformed_data.randomSplit([0.6, 0.2, 0.2], seed=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaOmQXWcArZW"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lQbkPiDcAq5V"
      },
      "outputs": [],
      "source": [
        "# Create a Logistic Regression model\n",
        "lr = LogisticRegression(maxIter=10, labelCol=label_column, featuresCol=\"features\")\n",
        "# Train the model\n",
        "lrModel = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9PwXfyO-wGR",
        "outputId": "63cddfcc-ba4c-422d-c753-fd778acd4fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------------+--------------------+\n",
            "| Model              | Logistic Regression   |                    |\n",
            "+====================+=======================+====================+\n",
            "| Metric             | Training              | Validation         |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Accuracy           | 0.8831928966699047    | 0.8795504738930949 |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Weighted Precision | 0.8751508919841021    | 0.870687028633707  |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Weighted Recall    | 0.8831928966699047    | 0.8795504738930949 |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| F1 Score           | 0.873417741176784     | 0.8693815107772412 |\n",
            "+--------------------+-----------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(lrModel, trainingData, validation_data=validationData, model_name='Logistic Regression', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn7ftf81Aj3c"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3TWOfuOx9AJV"
      },
      "outputs": [],
      "source": [
        "\n",
        " # Create Random Forest model\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol=label_column)\n",
        "\n",
        "# Fit model to training data\n",
        "rf_model = rf.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9hrOjY9AJW",
        "outputId": "12b75941-f2d0-488e-9e20-20223e5c88ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | Random Forest      |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Validation         |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.819188705399535  | 0.8193583088169379 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.6710701350541662 | 0.6713480382273527 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.819188705399535  | 0.8193583088169379 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.7377685811948619 | 0.7380053010711294 |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(rf_model, trainingData, validation_data=validationData, model_name='Random Forest', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqCb1jHCf2z"
      },
      "source": [
        "## GBTClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "8_jtI-eN_IfO",
        "outputId": "730ff1c7-fd12-4755-8c84-f01a8a8624b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(featuresCol='features', labelCol=label_column, maxIter=100)\n",
        "# Train model.  This also runs the indexers.\n",
        "gbt_model = gbt.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | GBTClassifier      |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Validation         |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.9336846069046814 | 0.9333615849136561 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.9317428329645383 | 0.9313862085110264 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.9336846069046814 | 0.9333615849136562 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.931868760107535  | 0.931480025006692  |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(gbt_model, trainingData, validation_data=validationData, model_name='GBTClassifier', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePzA52kxDpVt"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUmXa11LJ2Cb",
        "outputId": "16aa341d-1ba7-459d-8796-f8ec275cae9a"
      },
      "outputs": [],
      "source": [
        "lsvc = LinearSVC(featuresCol='features', labelCol=label_column,maxIter=100)\n",
        "# Fit the model\n",
        "lsvcModel = lsvc.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | SVM                |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Validation         |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.8885684192143551 | 0.8845135159363362 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.881558972706747  | 0.8768871708897702 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.888568419214355  | 0.8845135159363362 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.8818351978586784 | 0.8775174803568296 |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(lsvcModel, trainingData, validation_data=validationData, model_name='SVM', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the highest performing model on Train + Validation Data and test on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = trainingData.union(validationData)\n",
        "# Train a GBT model.\n",
        "gbt_model = gbt.fit(combined_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | GBTClassifier      |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Test               |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.9357418389437082 | 0.9345360866765039 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.9339385471483829 | 0.9326782945494004 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.9357418389437082 | 0.9345360866765039 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.9340707244461649 | 0.9328215721040373 |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(gbt_model, combined_data, test_data=testData, model_name='GBTClassifier', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pMFGgt9AJW"
      },
      "source": [
        " ## Save to HDFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YEr65Bs79AJW"
      },
      "outputs": [],
      "source": [
        "# model_path = \"./gbt_model\"\n",
        "# gbt_model.save(model_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MaOmQXWcArZW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v38_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
