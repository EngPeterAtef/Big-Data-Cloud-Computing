{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chbic3fo9AJR"
      },
      "source": [
        " ## Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfpbvgavADeB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7LveuaXi9AJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, VectorIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator,ClusteringEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LinearSVC,GBTClassifier\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcITIKfJAJ9G"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FtFnxOG2AMkv"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_data, validation_data = None, test_data = None, model_name = \"Model\", label_column = \"MIS_Status\"):\n",
        "    # Evaluate training data\n",
        "    train_predictions = model.transform(train_data)\n",
        "    train_metrics = calculate_metrics(train_predictions, label_column)\n",
        "\n",
        "     # Prepare data for tabulate\n",
        "    table = [\n",
        "        ['Model', model_name],\n",
        "        ['Metric', 'Training'],\n",
        "        ['Accuracy', train_metrics['accuracy']],\n",
        "        ['Weighted Precision', train_metrics['weighted_precision']],\n",
        "        ['Weighted Recall', train_metrics['weighted_recall']],\n",
        "        ['F1 Score', train_metrics['f1']]\n",
        "    ]\n",
        "    # Evaluate validation data\n",
        "    if validation_data is not None:\n",
        "        validation_predictions = model.transform(validation_data)\n",
        "        validation_metrics = calculate_metrics(validation_predictions, label_column)\n",
        "        table[0] += ['']\n",
        "        table[1] += ['Validation']\n",
        "        table[2] += [validation_metrics['accuracy']]\n",
        "        table[3] += [validation_metrics['weighted_precision']]\n",
        "        table[4] += [validation_metrics['weighted_recall']]\n",
        "        table[5] += [validation_metrics['f1']]\n",
        "\n",
        "    # Evaluate test data\n",
        "    if test_data is not None:\n",
        "        test_predictions = model.transform(test_data)\n",
        "        test_metrics = calculate_metrics(test_predictions, label_column)\n",
        "        table[0] += ['']\n",
        "        table[1] += ['Test']\n",
        "        table[2] += [test_metrics['accuracy']]\n",
        "        table[3] += [test_metrics['weighted_precision']]\n",
        "        table[4] += [test_metrics['weighted_recall']]\n",
        "        table[5] += [test_metrics['f1']]\n",
        "\n",
        "\n",
        "    # Display results using tabulate\n",
        "    print(tabulate(table, headers=\"firstrow\", tablefmt='grid'))\n",
        "\n",
        "def calculate_metrics(predictions, label_column):\n",
        "    evaluator_multi = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='accuracy')\n",
        "    evaluator_weighted_precision = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedPrecision')\n",
        "    evaluator_weighted_recall = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedRecall')\n",
        "    evaluator_f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='f1')\n",
        "\n",
        "    accuracy = evaluator_multi.evaluate(predictions)\n",
        "    weighted_precision = evaluator_weighted_precision.evaluate(predictions)\n",
        "    weighted_recall = evaluator_weighted_recall.evaluate(predictions)\n",
        "    f1 = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'weighted_precision': weighted_precision,\n",
        "        'weighted_recall': weighted_recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OcvZDw5A9AJT"
      },
      "outputs": [],
      "source": [
        "\n",
        "spark=SparkSession.builder\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .appName(\"LoanApproval\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HnF7W69AJU"
      },
      "source": [
        " ## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1HbGwdzc9AJU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# data_path=\"/content/drive/MyDrive/Colab Notebooks/BD_project/50000.csv\"\n",
        "data_path=\"../sample_data/1000.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JjluWYjC9AJU"
      },
      "outputs": [],
      "source": [
        "\n",
        "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"')\n",
        "# ======================================================\n",
        "# dropping these columns give better accuracy (by trial)\n",
        "# ======================================================\n",
        "loan_df = loan_df.drop('Name')\n",
        "loan_df = loan_df.drop('Zip')\n",
        "loan_df = loan_df.drop('City')\n",
        "# ======================================================\n",
        "# ======================================================\n",
        "# ======================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDD_RBf9AJU",
        "outputId": "b8665171-c592-4229-a752-3348289ba566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- State: string (nullable = true)\n",
            " |-- Bank: string (nullable = true)\n",
            " |-- BankState: string (nullable = true)\n",
            " |-- Term: integer (nullable = true)\n",
            " |-- NoEmp: integer (nullable = true)\n",
            " |-- NewExist: integer (nullable = true)\n",
            " |-- CreateJob: integer (nullable = true)\n",
            " |-- RetainedJob: integer (nullable = true)\n",
            " |-- UrbanRural: integer (nullable = true)\n",
            " |-- RevLineCr: integer (nullable = true)\n",
            " |-- LowDoc: integer (nullable = true)\n",
            " |-- Sector: integer (nullable = true)\n",
            " |-- ApprovalMonth: string (nullable = true)\n",
            " |-- IsFranchise: integer (nullable = true)\n",
            " |-- clean_DisbursementGross: double (nullable = true)\n",
            " |-- MIS_Status: integer (nullable = true)\n",
            " |-- clean_ChgOffPrinGr: double (nullable = true)\n",
            " |-- clean_GrAppv: double (nullable = true)\n",
            " |-- clean_SBA_Appv: double (nullable = true)\n",
            "\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+\n",
            "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|RetainedJob|UrbanRural|RevLineCr|LowDoc|Sector|ApprovalMonth|IsFranchise|clean_DisbursementGross|MIS_Status|clean_ChgOffPrinGr|clean_GrAppv|clean_SBA_Appv|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+\n",
            "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|          2|         1|        1|     0|    44|          Mar|          0|                25959.0|         1|               0.0|     10000.0|        5000.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|          7|         1|        1|     0|    23|          Jun|          0|                98479.0|         1|               0.0|     50000.0|       25000.0|\n",
            "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|          2|         1|        1|     0|    23|          Apr|          0|               135070.0|         1|               0.0|     35000.0|       17500.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|          4|         1|        0|     0|    72|          Mar|          0|                20000.0|         1|               0.0|     20000.0|       10000.0|\n",
            "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|          0|         0|        0|     1|    81|          Apr|          0|                50000.0|         1|               0.0|     50000.0|       45000.0|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loan_df.printSchema()\n",
        "loan_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPp_5zgk9AJU",
        "outputId": "b20f8619-2703-4c4d-ff6e-7a22d13a82f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transforming categorial features...\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+----------+-------------+---------+-----------------+--------------+--------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+------------------+----------------+--------------------+\n",
            "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|RetainedJob|UrbanRural|RevLineCr|LowDoc|Sector|ApprovalMonth|IsFranchise|clean_DisbursementGross|MIS_Status|clean_ChgOffPrinGr|clean_GrAppv|clean_SBA_Appv|StateIndex|     StateVec|BankIndex|          BankVec|BankStateIndex|  BankStateVec|UrbanRuralIndex|UrbanRuralVec|RevLineCrIndex| RevLineCrVec|LowDocIndex|    LowDocVec|SectorIndex|     SectorVec|ApprovalMonthIndex|ApprovalMonthVec|            features|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+----------+-------------+---------+-----------------+--------------+--------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+------------------+----------------+--------------------+\n",
            "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|          2|         1|        1|     0|    44|          Mar|          0|                25959.0|         1|               0.0|     10000.0|        5000.0|       0.0|(8,[0],[1.0])|      2.0|  (144,[2],[1.0])|           5.0|(21,[5],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        1.0|(17,[1],[1.0])|               3.0|  (11,[3],[1.0])|(215,[0,1,4,6,8,9...|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|          7|         1|        1|     0|    23|          Jun|          0|                98479.0|         1|               0.0|     50000.0|       25000.0|       0.0|(8,[0],[1.0])|      0.0|  (144,[0],[1.0])|           0.0|(21,[0],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        2.0|(17,[2],[1.0])|               0.0|  (11,[0],[1.0])|(215,[0,1,4,6,8,9...|\n",
            "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|          2|         1|        1|     0|    23|          Apr|          0|               135070.0|         1|               0.0|     35000.0|       17500.0|       0.0|(8,[0],[1.0])|    104.0|(144,[104],[1.0])|           1.0|(21,[1],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        2.0|(17,[2],[1.0])|               1.0|  (11,[1],[1.0])|(215,[0,1,4,6,8,9...|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|          4|         1|        0|     0|    72|          Mar|          0|                20000.0|         1|               0.0|     20000.0|       10000.0|       0.0|(8,[0],[1.0])|      0.0|  (144,[0],[1.0])|           0.0|(21,[0],[1.0])|            0.0|(2,[0],[1.0])|           0.0|(1,[0],[1.0])|        0.0|(1,[0],[1.0])|        6.0|(17,[6],[1.0])|               3.0|  (11,[3],[1.0])|(215,[0,1,4,6,8,9...|\n",
            "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|          0|         0|        0|     1|    81|          Apr|          0|                50000.0|         1|               0.0|     50000.0|       45000.0|       0.0|(8,[0],[1.0])|      1.0|  (144,[1],[1.0])|           1.0|(21,[1],[1.0])|            1.0|(2,[1],[1.0])|           0.0|(1,[0],[1.0])|        1.0|    (1,[],[])|        3.0|(17,[3],[1.0])|               1.0|  (11,[1],[1.0])|(215,[0,1,2,6,8,9...|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+------+-------------+-----------+-----------------------+----------+------------------+------------+--------------+----------+-------------+---------+-----------------+--------------+--------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+--------------+------------------+----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Splitting data into training, validation and test...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Transforming categorial features...\")\n",
        "# List of categorical columns to be one-hot encoded\n",
        "# categorical_columns = [\"Name\", \"City\", \"State\", \"Zip\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
        "categorical_columns = [\"State\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
        "\n",
        "# Define an empty list to store the pipeline stages\n",
        "stages = []\n",
        "\n",
        "# Iterate over each categorical column\n",
        "for column in categorical_columns:\n",
        "    # Define StringIndexer for the current column\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"Index\")\n",
        "\n",
        "    # Define OneHotEncoder for the indexed column\n",
        "    encoder = OneHotEncoder(inputCol=column + \"Index\", outputCol=column + \"Vec\")\n",
        "\n",
        "    # Add StringIndexer and OneHotEncoder to the list of stages\n",
        "    stages += [indexer, encoder]\n",
        "\n",
        "label_column = \"MIS_Status\"\n",
        "\n",
        "# Create VectorAssembler for combining all features\n",
        "# List of input columns (excluding the label column and categorical columns)\n",
        "input_columns = [col for col in loan_df.columns if col != label_column and col not in categorical_columns]\n",
        "input_columns += [column + \"Vec\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=input_columns , outputCol=\"features\")\n",
        "\n",
        "# Combine all stages into a Pipeline\n",
        "pipeline = Pipeline(stages=stages + [assembler])\n",
        "\n",
        "# Fit the pipeline to your data\n",
        "pipeline_model = pipeline.fit(loan_df)\n",
        "\n",
        "# Transform your data using the pipeline\n",
        "transformed_data = pipeline_model.transform(loan_df)\n",
        "transformed_data.show(5)\n",
        "print(\"Splitting data into training, validation and test...\")\n",
        "# Split the transformed data into training and test sets (60% training, 20% validation, 20% test)\n",
        "(trainingData, validationData, testData) = transformed_data.randomSplit([0.6, 0.2, 0.2], seed=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaOmQXWcArZW"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lQbkPiDcAq5V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training logistic regression model...\n"
          ]
        }
      ],
      "source": [
        "# Create a Logistic Regression model\n",
        "lr = LogisticRegression(maxIter=10, elasticNetParam=0.8, labelCol=label_column, featuresCol=\"features\")\n",
        "# Train the model\n",
        "lrModel = lr.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9PwXfyO-wGR",
        "outputId": "63cddfcc-ba4c-422d-c753-fd778acd4fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------------+--------------------+\n",
            "| Model              | Logistic Regression   |                    |\n",
            "+====================+=======================+====================+\n",
            "| Metric             | Training              | Validation         |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Accuracy           | 0.9983164983164983    | 0.9141414141414141 |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Weighted Precision | 0.9983197483197483    | 0.9094247068385    |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| Weighted Recall    | 0.9983164983164983    | 0.9141414141414141 |\n",
            "+--------------------+-----------------------+--------------------+\n",
            "| F1 Score           | 0.9983118099628471    | 0.9107172722883159 |\n",
            "+--------------------+-----------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(lrModel, trainingData, validation_data=validationData, model_name='Logistic Regression', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn7ftf81Aj3c"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3TWOfuOx9AJV"
      },
      "outputs": [],
      "source": [
        "\n",
        " # Create Random Forest model\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol=label_column)\n",
        "\n",
        "# Fit model to training data\n",
        "rf_model = rf.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_9hrOjY9AJW",
        "outputId": "12b75941-f2d0-488e-9e20-20223e5c88ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | Random Forest      |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Validation         |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.9074074074074074 | 0.8686868686868687 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.9121426250812217 | 0.8861952861952862 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.9074074074074074 | 0.8686868686868686 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.8853706284458559 | 0.8200306637806639 |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(rf_model, trainingData, validation_data=validationData, model_name='Random Forest', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqCb1jHCf2z"
      },
      "source": [
        "## GBTClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "8_jtI-eN_IfO",
        "outputId": "730ff1c7-fd12-4755-8c84-f01a8a8624b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(featuresCol='features', labelCol=label_column, maxIter=100)\n",
        "# Train model.  This also runs the indexers.\n",
        "gbt_model = gbt.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------+--------------------+\n",
            "| Model              | GBTClassifier   |                    |\n",
            "+====================+=================+====================+\n",
            "| Metric             | Training        | Validation         |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Accuracy           | 1.0             | 0.9949494949494949 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Weighted Precision | 1.0             | 0.9949792038027332 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Weighted Recall    | 1.0             | 0.9949494949494949 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| F1 Score           | 1.0             | 0.9949126413961066 |\n",
            "+--------------------+-----------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(gbt_model, trainingData, validation_data=validationData, model_name='GBTClassifier', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePzA52kxDpVt"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUmXa11LJ2Cb",
        "outputId": "16aa341d-1ba7-459d-8796-f8ec275cae9a"
      },
      "outputs": [],
      "source": [
        "lsvc = LinearSVC(featuresCol='features', labelCol=label_column,maxIter=100, regParam=0.1)\n",
        "# Fit the model\n",
        "lsvcModel = lsvc.fit(trainingData)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "| Model              | SVM                |                    |\n",
            "+====================+====================+====================+\n",
            "| Metric             | Training           | Validation         |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Accuracy           | 0.9225589225589226 | 0.8787878787878788 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Precision | 0.92625602429524   | 0.8762947349334784 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Weighted Recall    | 0.9225589225589226 | 0.8787878787878788 |\n",
            "+--------------------+--------------------+--------------------+\n",
            "| F1 Score           | 0.9086511372225657 | 0.8454545454545455 |\n",
            "+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(lsvcModel, trainingData, validation_data=validationData, model_name='SVM', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the highest performing model on Train + Validation Data and test on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = trainingData.union(validationData)\n",
        "# Train a GBT model.\n",
        "gbt_model = gbt.fit(combined_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------+--------------------+\n",
            "| Model              | GBTClassifier   |                    |\n",
            "+====================+=================+====================+\n",
            "| Metric             | Training        | Test               |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Accuracy           | 1.0             | 0.9855769230769231 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Weighted Precision | 1.0             | 0.9876373626373626 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| Weighted Recall    | 1.0             | 0.9855769230769231 |\n",
            "+--------------------+-----------------+--------------------+\n",
            "| F1 Score           | 1.0             | 0.9860742705570291 |\n",
            "+--------------------+-----------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(gbt_model, combined_data, test_data=testData, model_name='GBTClassifier', label_column=label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pMFGgt9AJW"
      },
      "source": [
        " ## Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YEr65Bs79AJW"
      },
      "outputs": [],
      "source": [
        "# model_path = \"./gbt_model\"\n",
        "# gbt_model.save(model_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MaOmQXWcArZW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v38_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
