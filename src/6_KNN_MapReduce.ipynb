{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.76611328125,
      "end_time": 1714665342189.737
     }
    },
    "id": "7vPTp1WIWPlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3</td><td>application_1714661326598_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-bd-tea.ukvgix2kknyuti4fk1kzz44f0a.milx.internal.cloudapp.net:8088/proxy/application_1714661326598_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn3-bd-tea.ukvgix2kknyuti4fk1kzz44f0a.milx.internal.cloudapp.net:30060/node/containerlogs/container_1714661326598_0007_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from tabulate import tabulate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 744.127197265625,
      "end_time": 1714665406554
     }
    },
    "id": "RhfzwjH7WZXn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LoanApproval\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.648193359375,
      "end_time": 1714665407553.475
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J6p0NgA2kNb",
    "outputId": "44192711-64a9-402c-faed-f8c35d5aa2d2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Bank: string (nullable = true)\n",
      " |-- BankState: string (nullable = true)\n",
      " |-- Term: integer (nullable = true)\n",
      " |-- NoEmp: integer (nullable = true)\n",
      " |-- NewExist: integer (nullable = true)\n",
      " |-- CreateJob: integer (nullable = true)\n",
      " |-- UrbanRural: integer (nullable = true)\n",
      " |-- RevLineCr: integer (nullable = true)\n",
      " |-- LowDoc: integer (nullable = true)\n",
      " |-- Sector: integer (nullable = true)\n",
      " |-- IsFranchise: integer (nullable = true)\n",
      " |-- clean_DisbursementGross: double (nullable = true)\n",
      " |-- MIS_Status: integer (nullable = true)\n",
      " |-- clean_GrAppv: double (nullable = true)\n",
      "\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
      "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|UrbanRural|RevLineCr|LowDoc|Sector|IsFranchise|clean_DisbursementGross|MIS_Status|clean_GrAppv|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
      "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|         1|        1|     0|    44|          0|                25959.0|         1|     10000.0|\n",
      "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|         1|        1|     0|    23|          0|                98479.0|         1|     50000.0|\n",
      "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|         1|        1|     0|    23|          0|               135070.0|         1|     35000.0|\n",
      "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|         1|        0|     0|    72|          0|                20000.0|         1|     20000.0|\n",
      "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|         0|        0|     1|    81|          0|                50000.0|         1|     50000.0|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "data_path=\"./50000_2.csv\"\n",
    "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"')\n",
    "loan_df.printSchema()\n",
    "loan_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 35.72705078125,
      "end_time": 1714665406600
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah6-76fa5Y7_",
    "outputId": "2b1eb904-5c9d-4d53-c4d4-b2580f422a0b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming categorial features...\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+---------+--------------+---------------+-----------+--------------+------------------+---------------+-------------+--------------+--------------------+\n",
      "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|UrbanRural|RevLineCr|LowDoc|Sector|IsFranchise|clean_DisbursementGross|MIS_Status|clean_GrAppv|StateIndex|BankIndex|BankStateIndex|UrbanRuralIndex|SectorIndex|      StateVec|           BankVec|   BankStateVec|UrbanRuralVec|     SectorVec|            features|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+---------+--------------+---------------+-----------+--------------+------------------+---------------+-------------+--------------+--------------------+\n",
      "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|         1|        1|     0|    44|          0|                25959.0|         1|     10000.0|       4.0|     11.0|           9.0|            0.0|        1.0|(51,[4],[1.0])| (2946,[11],[1.0])| (53,[9],[1.0])|(3,[0],[1.0])|(21,[1],[1.0])|(3083,[0,1,4,7,8,...|\n",
      "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|         1|        1|     0|    23|          0|                98479.0|         1|     50000.0|       4.0|      3.0|           4.0|            0.0|        3.0|(51,[4],[1.0])|  (2946,[3],[1.0])| (53,[4],[1.0])|(3,[0],[1.0])|(21,[3],[1.0])|(3083,[0,1,4,7,8,...|\n",
      "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|         1|        1|     0|    23|          0|               135070.0|         1|     35000.0|       4.0|    501.0|          11.0|            0.0|        3.0|(51,[4],[1.0])|(2946,[501],[1.0])|(53,[11],[1.0])|(3,[0],[1.0])|(21,[3],[1.0])|(3083,[0,1,4,7,8,...|\n",
      "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|         1|        0|     0|    72|          0|                20000.0|         1|     20000.0|       4.0|      3.0|           4.0|            0.0|        6.0|(51,[4],[1.0])|  (2946,[3],[1.0])| (53,[4],[1.0])|(3,[0],[1.0])|(21,[6],[1.0])|(3083,[0,1,7,8,13...|\n",
      "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|         0|        0|     1|    81|          0|                50000.0|         1|     50000.0|       4.0|      0.0|          11.0|            1.0|        4.0|(51,[4],[1.0])|  (2946,[0],[1.0])|(53,[11],[1.0])|(3,[1],[1.0])|(21,[4],[1.0])|(3083,[0,1,2,5,7,...|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+----------+---------+--------------+---------------+-----------+--------------+------------------+---------------+-------------+--------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Transforming categorial features...\")\n",
    "# List of categorical columns to be one-hot encoded\n",
    "categorical_columns = [\"State\", \"Bank\", \"BankState\", \"UrbanRural\", \"Sector\"]\n",
    "\n",
    "# Define an empty list to store the pipeline stages\n",
    "stages = []\n",
    "\n",
    "# Fit StringIndexer on the entire dataset and add to stages\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"Index\").fit(loan_df) for column in categorical_columns]\n",
    "stages += indexers\n",
    "\n",
    "# Define OneHotEncoder for the indexed columns\n",
    "encoders = [OneHotEncoder(inputCol=column + \"Index\", outputCol=column + \"Vec\", dropLast=False) for column in categorical_columns]\n",
    "stages += encoders\n",
    "\n",
    "\n",
    "label_column = \"MIS_Status\"\n",
    "\n",
    "# Create VectorAssembler for combining all features\n",
    "# List of input columns (excluding the label column and categorical columns)\n",
    "input_columns = [col for col in loan_df.columns if col != label_column and col not in categorical_columns]\n",
    "input_columns += [column + \"Vec\" for column in categorical_columns]\n",
    "assembler = VectorAssembler(inputCols=input_columns, outputCol=\"features\")\n",
    "\n",
    "# Combine all stages into a Pipeline\n",
    "pipeline = Pipeline(stages=stages + [assembler])\n",
    "\n",
    "# Fit the pipeline to your data\n",
    "pipeline_model = pipeline.fit(loan_df)\n",
    "\n",
    "# Transform your data using the pipeline\n",
    "transformed_data = pipeline_model.transform(loan_df)\n",
    "transformed_data.show(5)\n",
    "\n",
    "\n",
    "# Split the transformed data into training and test sets (60% training, 20% validation, 20% test)\n",
    "(trainingData, validationData, testData) = transformed_data.randomSplit([0.6, 0.2, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBGK4OcjX-zg"
   },
   "source": [
    "## Make a new DF that has only MIS_Status and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.359130859375,
      "end_time": 1714665407597.339
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeQn5Pm753VE",
    "outputId": "c1db1fc4-178d-41f0-ab3e-32e5fb1dde53"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------------------------------------------------------------------------+\n",
      "|MIS_Status|features                                                                                  |\n",
      "+----------+------------------------------------------------------------------------------------------+\n",
      "|1         |(3083,[0,1,7,8,56,1464,3056,3059,3069],[85.0,68.0,600000.0,600000.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|1         |(3083,[0,1,7,8,56,102,3007,3060,3062],[36.0,10.0,90000.0,90000.0,1.0,1.0,1.0,1.0,1.0])    |\n",
      "|1         |(3083,[0,1,7,8,56,182,3025,3061,3062],[240.0,9.0,1000000.0,1000000.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|0         |(3083,[0,1,3,7,8,56,84,3045,3059,3064],[22.0,2.0,1.0,25000.0,25000.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|0         |(3083,[0,1,7,8,56,66,3014,3059,3063],[48.0,9.0,50000.0,50000.0,1.0,1.0,1.0,1.0,1.0])      |\n",
      "+----------+------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "training_df = trainingData.select(\"MIS_Status\", \"features\")\n",
    "validation_df = validationData.select(\"MIS_Status\", \"features\")\n",
    "test_df = testData.select(\"MIS_Status\", \"features\")\n",
    "training_df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nsm8sdZYHV2"
   },
   "source": [
    "## Convert to RDD to Apply MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 23771.15185546875,
      "end_time": 1714665430386
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAXKR0KA6rXo",
    "outputId": "ccec9662-6e03-44ec-a2a5-9a4dbd33b271"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(MIS_Status=1, features=SparseVector(3083, {0: 85.0, 1: 68.0, 7: 600000.0, 8: 600000.0, 56: 1.0, 1464: 1.0, 3056: 1.0, 3059: 1.0, 3069: 1.0})), Row(MIS_Status=1, features=SparseVector(3083, {0: 36.0, 1: 10.0, 7: 90000.0, 8: 90000.0, 56: 1.0, 102: 1.0, 3007: 1.0, 3060: 1.0, 3062: 1.0})), Row(MIS_Status=1, features=SparseVector(3083, {0: 240.0, 1: 9.0, 7: 1000000.0, 8: 1000000.0, 56: 1.0, 182: 1.0, 3025: 1.0, 3061: 1.0, 3062: 1.0})), Row(MIS_Status=0, features=SparseVector(3083, {0: 22.0, 1: 2.0, 3: 1.0, 7: 25000.0, 8: 25000.0, 56: 1.0, 84: 1.0, 3045: 1.0, 3059: 1.0, 3064: 1.0})), Row(MIS_Status=0, features=SparseVector(3083, {0: 48.0, 1: 9.0, 7: 50000.0, 8: 50000.0, 56: 1.0, 66: 1.0, 3014: 1.0, 3059: 1.0, 3063: 1.0}))]"
     ]
    }
   ],
   "source": [
    "training_rdd = training_df.rdd\n",
    "validation_rdd = validation_df.rdd\n",
    "test_rdd = test_df.rdd\n",
    "print(training_rdd.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 87073,
      "end_time": 1714665430386
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k1jCNLL_nm7",
    "outputId": "c68aac35-2a83-4f38-8c08-35de2aa2e99c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions before repartitioning: 1\n",
      "Number of partitions after repartitioning: 120"
     ]
    }
   ],
   "source": [
    "print(\"Number of partitions before repartitioning:\", training_rdd.getNumPartitions())\n",
    "# Repartition the RDD into a new number of partitions\n",
    "num_partitions = 120  # Change this to the desired number of partitions\n",
    "training_rdd = training_rdd.repartition(num_partitions)\n",
    "# New number of partitions\n",
    "print(\"Number of partitions after repartitioning:\", training_rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.822998046875,
      "end_time": 1714665579202.64
     }
    },
    "id": "AWLIV0vGXg7R"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect the elements of the RDD into a list\n",
    "validation_list = validation_rdd.collect()\n",
    "test_list = test_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0ZwyDGbXk6f"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 7949.7890625,
      "end_time": 1714665585727
     }
    },
    "id": "WwIh7JLp9Spq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def appy_knn(rdd, query_point, k):\n",
    "  def cosine_similarity(np_vector1, np_vector2):\n",
    "    # Compute dot product\n",
    "    dot_product = np.dot(np_vector1, np_vector2)\n",
    "\n",
    "    # Compute magnitudes\n",
    "    mag1 = np.sqrt(np.sum(np_vector1 ** 2))\n",
    "    mag2 = np.sqrt(np.sum(np_vector2 ** 2))\n",
    "\n",
    "    # Handle division by zero\n",
    "    if mag1 == 0 or mag2 == 0:\n",
    "        return 0\n",
    "    # Compute cosine similarity\n",
    "    return dot_product / (mag1 * mag2)\n",
    "\n",
    "  def map_phase(split):\n",
    "      \"\"\"Map phase: Find k-nearest neighbors in each split.\"\"\"\n",
    "      neighbors = []\n",
    "      for row in split:\n",
    "          true_class = row.MIS_Status\n",
    "          data_point = row.features\n",
    "          # Convert PySpark sparse vectors to NumPy arrays\n",
    "          np_vector1 = np.array(query_point.toArray())\n",
    "          np_vector2 = np.array(data_point.toArray())\n",
    "          # Calculate cosine similarity\n",
    "          dist = cosine_similarity(np_vector1, np_vector2)\n",
    "          neighbors.append((None, {'similarity': dist, 'class': true_class}))\n",
    "      # Sort the neighbors by similarity\n",
    "      neighbors.sort(key=lambda x: x[1]['similarity'], reverse=True)\n",
    "      # Take the top k neighbors\n",
    "      k_neighbors = neighbors[:k]\n",
    "\n",
    "      return [k_neighbors]\n",
    "\n",
    "  def reduce_phase(neighbors1, neighbors2):\n",
    "      \"\"\"Reduce phase: Find the definitive top k neighbors.\"\"\"\n",
    "      # Merge the neighbors from different splits\n",
    "      merged_neighbors = neighbors1 + neighbors2\n",
    "      # Sort the merged neighbors by distance\n",
    "      merged_neighbors.sort(key=lambda x: x[1]['similarity'], reverse=True)\n",
    "      # Take the top k neighbors\n",
    "      return merged_neighbors[:k]\n",
    "\n",
    "  def classify_input(data):\n",
    "    # Extract the classes from the data\n",
    "    classes = np.array([entry[1]['class'] for entry in data])\n",
    "\n",
    "    # Count the occurrences of each class\n",
    "    class_counts = np.bincount(classes)\n",
    "\n",
    "    # Find the most common class\n",
    "    most_common_class = np.argmax(class_counts)\n",
    "\n",
    "    # print(\"Most frequent class:\", most_common_class)\n",
    "    return most_common_class\n",
    "\n",
    "  # Map phase: Apply map transformation to each split of the training data\n",
    "  mapped_neighbors = rdd.mapPartitions(map_phase)\n",
    "  # print(\"mapped_neighbors_rdd\")\n",
    "  # print(\"Number of partitions:\", mapped_neighbors.getNumPartitions())\n",
    "  # print(mapped_neighbors.take(10))\n",
    "\n",
    "  # Reduce phase: Aggregate results from the map phase using reduce\n",
    "  final_neighbors = mapped_neighbors.reduce(reduce_phase)\n",
    "  # print(\"Final K Nearest Neighbors:\", final_neighbors)\n",
    "  return classify_input(final_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKmtLNmbXUAk"
   },
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.60498046875,
      "end_time": 1714665586709.087
     }
    },
    "id": "bw9VS-N5LBMF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_confusion_matrix(true_labels, predicted_labels, labels):\n",
    "    num_classes = len(labels)\n",
    "    confusion_matrix = [[0] * num_classes for _ in range(num_classes)]\n",
    "    label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        true_index = label_to_index[true_label]\n",
    "        predicted_index = label_to_index[predicted_label]\n",
    "        confusion_matrix[true_index][predicted_index] += 1\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def calculate_accuracy(confusion_matrix):\n",
    "    tp_tn = sum(confusion_matrix[i][i] for i in range(len(confusion_matrix)))\n",
    "    tp_tn_fp_fn = sum(sum(row) for row in confusion_matrix)\n",
    "    accuracy = tp_tn / tp_tn_fp_fn\n",
    "    return accuracy\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2* (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_precision(confusion_matrix, class_index):\n",
    "    # Calculate precision for a specific class\n",
    "    true_positive = confusion_matrix[class_index][class_index]\n",
    "    column_sum = sum(confusion_matrix[i][class_index] for i in range(len(confusion_matrix)))\n",
    "    precision = true_positive / column_sum if column_sum != 0 else 0\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(confusion_matrix, class_index):\n",
    "    # Calculate recall for a specific class\n",
    "    true_positive = confusion_matrix[class_index][class_index]\n",
    "    row_sum = sum(confusion_matrix[class_index])\n",
    "    recall = true_positive / row_sum if row_sum != 0 else 0\n",
    "    return recall\n",
    "\n",
    "def calculate_macro_average_precision(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precisions = [calculate_precision(confusion_matrix, i) for i in range(num_classes)]\n",
    "    macro_average_precision = sum(precisions) / num_classes\n",
    "    return macro_average_precision\n",
    "\n",
    "def calculate_macro_average_recall(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    recalls = [calculate_recall(confusion_matrix, i) for i in range(num_classes)]\n",
    "    macro_average_recall = sum(recalls) / num_classes\n",
    "    return macro_average_recall\n",
    "\n",
    "\n",
    "def calculate_micro_average_precision(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    true_positives = sum(confusion_matrix[i][i] for i in range(num_classes))\n",
    "    all_positives = sum(sum(confusion_matrix[i]) for i in range(num_classes))\n",
    "    micro_average_precision = true_positives / all_positives if all_positives != 0 else 0\n",
    "    return micro_average_precision\n",
    "\n",
    "def calculate_micro_average_recall(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    true_positives = sum(confusion_matrix[i][i] for i in range(num_classes))\n",
    "    all_actuals = sum(sum(row) for row in confusion_matrix)\n",
    "    micro_average_recall = true_positives / all_actuals if all_actuals != 0 else 0\n",
    "    return micro_average_recall\n",
    "def display_confusion_matrix(confusion_matrix, labels):\n",
    "    print(\"Confusion Matrix:\")\n",
    "     # Prepare data for tabulate\n",
    "    table = [\n",
    "        ['', *labels],\n",
    "        [labels[0],*confusion_matrix[0]],\n",
    "        [labels[1],*confusion_matrix[1]]\n",
    "    ]\n",
    "    # Display results using tabulate\n",
    "    print(tabulate(table, tablefmt='grid'))\n",
    "\n",
    "def evaluate_knn(test_list):\n",
    "    predicted_list = []\n",
    "    true_list = []\n",
    "    for row in test_list:\n",
    "        true_label = row.MIS_Status\n",
    "        point = row.features\n",
    "        # =========================================\n",
    "        # =======Apply KNN to the test point=======\n",
    "        # =========================================\n",
    "        knn_predict = appy_knn(training_rdd, point, 3)\n",
    "        predicted_list.append(knn_predict)\n",
    "        true_list.append(true_label)\n",
    "    labels = [1,0]\n",
    "    confusion_matrix= calculate_confusion_matrix(true_list, predicted_list, labels=labels)\n",
    "    display_confusion_matrix(confusion_matrix, labels)\n",
    "\n",
    "    accuracy = calculate_accuracy(confusion_matrix)\n",
    "\n",
    "    macro_precision = calculate_macro_average_precision(confusion_matrix)\n",
    "    micro_precision = calculate_micro_average_precision(confusion_matrix)\n",
    "\n",
    "    macro_recall = calculate_macro_average_recall(confusion_matrix)\n",
    "    micro_recall = calculate_micro_average_recall(confusion_matrix)\n",
    "\n",
    "    f1_macro = calculate_f1_score(macro_precision,macro_recall)\n",
    "    f1_micro = calculate_f1_score(micro_precision,micro_recall)\n",
    "    # Prepare data for tabulate\n",
    "    table = [\n",
    "        ['Accuracy', accuracy],\n",
    "        ['Macro Precision', macro_precision],\n",
    "        ['Micro Precision', micro_precision],\n",
    "        ['Macro Recall', macro_recall],\n",
    "        ['Micro Recall', micro_recall],\n",
    "        ['Macro F1', f1_macro],\n",
    "        ['Micro F1', f1_micro]\n",
    "    ]\n",
    "    print(tabulate(table, tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 0.404052734375,
      "end_time": 1714666460440.801
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJiSuP26V7tO",
    "outputId": "b9fb60fd-8397-44b8-cd50-9da915441407"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "+---+-----+----+\n",
      "|   |   1 |  0 |\n",
      "+---+-----+----+\n",
      "| 1 | 323 | 19 |\n",
      "+---+-----+----+\n",
      "| 0 | 120 | 38 |\n",
      "+---+-----+----+\n",
      "+-----------------+----------+\n",
      "| Accuracy        | 0.722    |\n",
      "+-----------------+----------+\n",
      "| Macro Precision | 0.697893 |\n",
      "+-----------------+----------+\n",
      "| Micro Precision | 0.722    |\n",
      "+-----------------+----------+\n",
      "| Macro Recall    | 0.592475 |\n",
      "+-----------------+----------+\n",
      "| Micro Recall    | 0.722    |\n",
      "+-----------------+----------+\n",
      "| Macro F1        | 0.640878 |\n",
      "+-----------------+----------+\n",
      "| Micro F1        | 0.722    |\n",
      "+-----------------+----------+"
     ]
    }
   ],
   "source": [
    "evaluate_knn(validation_list[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7KJwM1OjxsB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "v38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "python3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
