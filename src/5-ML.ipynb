{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import col, countDistinct, isnan, when, count, round, substring_index,substring, split, regexp_replace, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LinearSVC\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"LoanApproval\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc=spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Read Data - SBAnational.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path=\"../sample_data/50000.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zip: integer (nullable = true)\n",
      " |-- Bank: string (nullable = true)\n",
      " |-- BankState: string (nullable = true)\n",
      " |-- Term: integer (nullable = true)\n",
      " |-- NoEmp: integer (nullable = true)\n",
      " |-- NewExist: integer (nullable = true)\n",
      " |-- CreateJob: integer (nullable = true)\n",
      " |-- RetainedJob: integer (nullable = true)\n",
      " |-- UrbanRural: integer (nullable = true)\n",
      " |-- RevLineCr: integer (nullable = true)\n",
      " |-- LowDoc: integer (nullable = true)\n",
      " |-- MIS_Status: integer (nullable = true)\n",
      " |-- Sector: integer (nullable = true)\n",
      " |-- ApprovalMonth: string (nullable = true)\n",
      " |-- IsFranchise: integer (nullable = true)\n",
      " |-- clean_GrAppv: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+-----+----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+\n",
      "|                Name|                City|State| Zip|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|RetainedJob|UrbanRural|RevLineCr|LowDoc|MIS_Status|Sector|ApprovalMonth|IsFranchise|clean_GrAppv|\n",
      "+--------------------+--------------------+-----+----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+\n",
      "|KC Countertops, Inc.|              Ludlow|   MA|1056|TD BANK, NATIONAL...|       DE|  36|    2|       1|        0|          2|         1|        1|     0|         1|    31|          Feb|          0|     15000.0|\n",
      "|THE HOLBEK GROUP INC|ORANGE (CENSUS NA...|   MA|1364|GREENFIELD CO-OPE...|       MA|  84|   20|       0|        0|         20|         2|        1|     0|         1|    31|          Jul|          0|     50000.0|\n",
      "|PRINTED CIRCUIT CORP|              WOBURN|   MA|1801|MASSACHUSETTS BUS...|       MA| 120|  210|       0|        0|          0|         0|        0|     0|         1|    31|          Mar|          0|    800000.0|\n",
      "|MAUI MOUNT & MACHINE|         LOCKERVILLE|   MA|1854|CITIZENS BANK NAT...|       MA|  84|    1|       0|        1|          2|         1|        1|     0|         1|    31|          Sep|          0|     10000.0|\n",
      "|MLS Sheet Metal, LLC|           TEWKSBURY|   MA|1876|ENTERPRISE BK & T...|       MA|  84|    3|       1|        3|          6|         1|        1|     0|         1|    31|          Nov|          0|    200000.0|\n",
      "+--------------------+--------------------+-----+----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_df.printSchema()\n",
    "loan_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming categorial features...\n",
      "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+-------------+------------------+----------------+--------------------+\n",
      "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|RetainedJob|UrbanRural|RevLineCr|LowDoc|MIS_Status|Sector|ApprovalMonth|IsFranchise|clean_GrAppv|StateIndex|      StateVec|BankIndex|           BankVec|BankStateIndex|   BankStateVec|UrbanRuralIndex|UrbanRuralVec|RevLineCrIndex| RevLineCrVec|LowDocIndex|    LowDocVec|SectorIndex|    SectorVec|ApprovalMonthIndex|ApprovalMonthVec|            features|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+-------------+------------------+----------------+--------------------+\n",
      "|   MA|TD BANK, NATIONAL...|       DE|  36|    2|       1|        0|          2|         1|        1|     0|         1|    31|          Feb|          0|     15000.0|       6.0|(50,[6],[1.0])|     10.0| (2650,[10],[1.0])|           9.0| (51,[9],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        0.0|(2,[0],[1.0])|              10.0| (11,[10],[1.0])|(2775,[0,1,2,4,6,...|\n",
      "|   MA|GREENFIELD CO-OPE...|       MA|  84|   20|       0|        0|         20|         2|        1|     0|         1|    31|          Jul|          0|     50000.0|       6.0|(50,[6],[1.0])|    686.0|(2650,[686],[1.0])|          14.0|(51,[14],[1.0])|            2.0|    (2,[],[])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        0.0|(2,[0],[1.0])|               4.0|  (11,[4],[1.0])|(2775,[0,1,4,6,13...|\n",
      "|   MA|MASSACHUSETTS BUS...|       MA| 120|  210|       0|        0|          0|         0|        0|     0|         1|    31|          Mar|          0|    800000.0|       6.0|(50,[6],[1.0])|    402.0|(2650,[402],[1.0])|          14.0|(51,[14],[1.0])|            1.0|(2,[1],[1.0])|           0.0|(1,[0],[1.0])|        0.0|(1,[0],[1.0])|        0.0|(2,[0],[1.0])|               1.0|  (11,[1],[1.0])|(2775,[0,1,6,13,4...|\n",
      "|   MA|CITIZENS BANK NAT...|       MA|  84|    1|       0|        1|          2|         1|        1|     0|         1|    31|          Sep|          0|     10000.0|       6.0|(50,[6],[1.0])|      1.0|  (2650,[1],[1.0])|          14.0|(51,[14],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        0.0|(2,[0],[1.0])|               0.0|  (11,[0],[1.0])|(2775,[0,1,3,4,6,...|\n",
      "|   MA|ENTERPRISE BK & T...|       MA|  84|    3|       1|        3|          6|         1|        1|     0|         1|    31|          Nov|          0|    200000.0|       6.0|(50,[6],[1.0])|    108.0|(2650,[108],[1.0])|          14.0|(51,[14],[1.0])|            0.0|(2,[0],[1.0])|           1.0|    (1,[],[])|        0.0|(1,[0],[1.0])|        0.0|(2,[0],[1.0])|               9.0|  (11,[9],[1.0])|(2775,[0,1,2,3,4,...|\n",
      "+-----+--------------------+---------+----+-----+--------+---------+-----------+----------+---------+------+----------+------+-------------+-----------+------------+----------+--------------+---------+------------------+--------------+---------------+---------------+-------------+--------------+-------------+-----------+-------------+-----------+-------------+------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Splitting data into training, validation and test...\n",
      "Training logistic regression model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Transforming categorial features...\")\n",
    "# List of categorical columns to be one-hot encoded\n",
    "categorical_columns = [\"Name\", \"City\", \"State\", \"Zip\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
    "# ======================================================\n",
    "# dropping these columns give better accuracy (by trial)\n",
    "# ======================================================\n",
    "loan_df = loan_df.drop('Name')\n",
    "categorical_columns = [\"City\", \"State\", \"Zip\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
    "\n",
    "loan_df = loan_df.drop('Zip')\n",
    "categorical_columns = [\"City\", \"State\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
    "\n",
    "loan_df = loan_df.drop('City')\n",
    "categorical_columns = [\"State\", \"Bank\", \"BankState\", \"UrbanRural\", \"RevLineCr\", \"LowDoc\", \"Sector\", \"ApprovalMonth\"]\n",
    "# ======================================================\n",
    "# ======================================================\n",
    "# ======================================================\n",
    "\n",
    "# Define an empty list to store the pipeline stages\n",
    "stages = []\n",
    "\n",
    "# Iterate over each categorical column\n",
    "for column in categorical_columns:\n",
    "    # Define StringIndexer for the current column\n",
    "    indexer = StringIndexer(inputCol=column, outputCol=column + \"Index\")\n",
    "    \n",
    "    # Define OneHotEncoder for the indexed column\n",
    "    encoder = OneHotEncoder(inputCol=column + \"Index\", outputCol=column + \"Vec\")\n",
    "    \n",
    "    # Add StringIndexer and OneHotEncoder to the list of stages\n",
    "    stages += [indexer, encoder]\n",
    "label_column = \"MIS_Status\"\n",
    "\n",
    "\n",
    "\n",
    "# Create VectorAssembler for combining all features\n",
    "# List of input columns (excluding the label column and categorical columns)\n",
    "input_columns = [col for col in loan_df.columns if col != label_column and col not in categorical_columns]\n",
    "input_columns += [column + \"Vec\" for column in categorical_columns]\n",
    "assembler = VectorAssembler(inputCols=input_columns , outputCol=\"features\")\n",
    "\n",
    "# Combine all stages into a Pipeline\n",
    "pipeline = Pipeline(stages=stages + [assembler])\n",
    "\n",
    "# Fit the pipeline to your data\n",
    "pipeline_model = pipeline.fit(loan_df)\n",
    "\n",
    "# Transform your data using the pipeline\n",
    "transformed_data = pipeline_model.transform(loan_df)\n",
    "transformed_data.show(5)\n",
    "print(\"Splitting data into training, validation and test...\")\n",
    "# Split the transformed data into training and test sets (70% training, 30% test)\n",
    "# (trainingData, testData) = transformed_data.randomSplit([0.7, 0.3])\n",
    "(trainingData, validationData, testData) = transformed_data.randomSplit([0.6, 0.2, 0.2], seed=123)\n",
    "\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "lr = LogisticRegression(maxIter=10, elasticNetParam=0.8, labelCol=label_column, featuresCol=\"features\")\n",
    "print(\"Training logistic regression model...\")\n",
    "# Train the model\n",
    "lrModel = lr.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7553429289768673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lrModel.transform(validationData)\n",
    "\n",
    "# predictions.describe().show()\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=label_column)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data, model_name , date_type):\n",
    "\n",
    "    # prdict on data\n",
    "    predictions = model.transform(data)\n",
    "\n",
    "    # Create evaluators for different metrics\n",
    "    evaluator_multi = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='accuracy')\n",
    "    evaluator_weighted_precision = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedPrecision')\n",
    "    evaluator_weighted_recall = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=label_column, metricName='f1')\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = evaluator_multi.evaluate(predictions)\n",
    "    weighted_precision = evaluator_weighted_precision.evaluate(predictions)\n",
    "    weighted_recall = evaluator_weighted_recall.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    # Print results\n",
    "    print('-------------------------------------------------------------------------------------------------------------------')\n",
    "    print(f'---------------------------------------------- Model: {model_name} -----------------------------------------------')\n",
    "    print('-------------------------------------------------------------------------------------------------------------------')\n",
    "    print(f'Data Type: {date_type}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Weighted Precision: {weighted_precision}')\n",
    "    print(f'Weighted Recall: {weighted_recall}')\n",
    "    print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # Create Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol=label_column)\n",
    "\n",
    "# Fit model to training data\n",
    "rf_model = rf.fit(trainingData)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------- Model: Random Forest -----------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Data Type: train\n",
      "Accuracy: 0.8186359978540773\n",
      "Weighted Precision: 0.6701648969825408\n",
      "Weighted Recall: 0.8186359978540773\n",
      "F1 Score: 0.7369972856286915\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------- Model: Random Forest -----------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Data Type: validation\n",
      "Accuracy: 0.8144818729625605\n",
      "Weighted Precision: 0.6633807213846006\n",
      "Weighted Recall: 0.8144818729625605\n",
      "F1 Score: 0.7312067772840061\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------- Model: Random Forest -----------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Data Type: test\n",
      "Accuracy: 0.8105043270665473\n",
      "Weighted Precision: 0.6569172641935966\n",
      "Weighted Recall: 0.8105043270665473\n",
      "F1 Score: 0.7256732330023875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate_model(rf_model, trainingData, 'Random Forest', 'train')\n",
    "evaluate_model(rf_model, validationData, 'Random Forest', 'validation')\n",
    "evaluate_model(rf_model, testData, 'Random Forest', 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"lrModel\"\n",
    "# lrModel.save(model_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
