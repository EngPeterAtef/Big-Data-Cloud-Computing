{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chbic3fo9AJR"
      },
      "source": [
        " # Preprocessing and Cleaning 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfpbvgavADeB"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7LveuaXi9AJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OcvZDw5A9AJT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# spark=SparkSession.builder\\\n",
        "#     .master(\"local[*]\")\\\n",
        "#     .appName(\"LoanApproval\")\\\n",
        "#     .getOrCreate()\n",
        "spark=SparkSession.builder\\\n",
        "    .appName(\"LoanApproval\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HnF7W69AJU"
      },
      "source": [
        " ## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1HbGwdzc9AJU"
      },
      "outputs": [],
      "source": [
        "data_path=\"../data/preprocessed.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JjluWYjC9AJU"
      },
      "outputs": [],
      "source": [
        "\n",
        "loan_df =  spark.read.csv(data_path, header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"')\n",
        "loan_df = loan_df.drop('ApprovalMonth')\n",
        "loan_df = loan_df.drop('clean_ChgOffPrinGr')\n",
        "loan_df = loan_df.drop('RetainedJob')\n",
        "loan_df = loan_df.drop('clean_SBA_Appv')\n",
        "loan_df = loan_df.drop('Name')\n",
        "loan_df = loan_df.drop('Zip')\n",
        "loan_df = loan_df.drop('City')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDD_RBf9AJU",
        "outputId": "b8665171-c592-4229-a752-3348289ba566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- State: string (nullable = true)\n",
            " |-- Bank: string (nullable = true)\n",
            " |-- BankState: string (nullable = true)\n",
            " |-- Term: integer (nullable = true)\n",
            " |-- NoEmp: integer (nullable = true)\n",
            " |-- NewExist: integer (nullable = true)\n",
            " |-- CreateJob: integer (nullable = true)\n",
            " |-- UrbanRural: integer (nullable = true)\n",
            " |-- RevLineCr: integer (nullable = true)\n",
            " |-- LowDoc: integer (nullable = true)\n",
            " |-- Sector: integer (nullable = true)\n",
            " |-- IsFranchise: integer (nullable = true)\n",
            " |-- clean_DisbursementGross: double (nullable = true)\n",
            " |-- MIS_Status: integer (nullable = true)\n",
            " |-- clean_GrAppv: double (nullable = true)\n",
            "\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "|State|                Bank|BankState|Term|NoEmp|NewExist|CreateJob|UrbanRural|RevLineCr|LowDoc|Sector|IsFranchise|clean_DisbursementGross|MIS_Status|clean_GrAppv|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "|   MA|TD BANK, NATIONAL...|       DE|  84|    2|       0|        0|         1|        1|     0|    44|          0|                25959.0|         1|     10000.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    7|       0|        0|         1|        1|     0|    23|          0|                98479.0|         1|     50000.0|\n",
            "|   MA|FLORENCE SAVINGS ...|       MA|  60|    2|       0|        0|         1|        1|     0|    23|          0|               135070.0|         1|     35000.0|\n",
            "|   MA|CITIZENS BANK NAT...|       RI|  84|    4|       0|        0|         1|        0|     0|    72|          0|                20000.0|         1|     20000.0|\n",
            "|   MA|BANK OF AMERICA N...|       MA|  84|    6|       1|        0|         0|        0|     1|    81|          0|                50000.0|         1|     50000.0|\n",
            "+-----+--------------------+---------+----+-----+--------+---------+----------+---------+------+------+-----------+-----------------------+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loan_df.printSchema()\n",
        "loan_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save to HDFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# output_path = \"../data/preprocessed_2.csv\"\n",
        "\n",
        "# # Save the DataFrame to a CSV file\n",
        "# loan_df.write.csv(output_path, header=True, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save using pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert PySpark DataFrame to Pandas DataFrame\n",
        "pandas_df = loan_df.toPandas()\n",
        "\n",
        "# Specify the path where you want to save the CSV file\n",
        "output_path = \"../data/preprocessed_2.csv\"\n",
        "\n",
        "# Save the Pandas DataFrame to a CSV file\n",
        "pandas_df.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = 50000\n",
        "# Save a sample\n",
        "output_path = f\"../sample_data/{sample_size}_2.csv\"\n",
        "\n",
        "# Save the first 50000 rows of the Pandas DataFrame to a CSV file\n",
        "pandas_df.head(sample_size).to_csv(output_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MaOmQXWcArZW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v38_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
